{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "from random import randrange # used to pick MAD parameters\n",
    "\n",
    "class MapBase(MutableMapping):\n",
    "    \"\"\"Our own abstract base class that includes a nonpublic _Item class.\"\"\"\n",
    "    #------------------------------- nested _Item class -------------------------------\n",
    "    class _Item:\n",
    "        \"\"\"Lightweight composite to store key-value pairs as map items.\"\"\"\n",
    "        __slots__ = '_key', '_value'\n",
    "        def __init__(self, k, v):\n",
    "            self._key = k\n",
    "            self._value = v\n",
    "        def __eq__(self, other):\n",
    "            return self._key == other._key # compare items based on their keys\n",
    "        def __ne__(self, other):\n",
    "            return not (self == other) # opposite of __eq__\n",
    "        def __lt__(self, other):\n",
    "            return self._key < other._key # compare items based on their keys\n",
    "\n",
    "class UnsortedTableMap(MapBase):\n",
    "  \"\"\"Map implementation using an unordered list.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    \"\"\"Create an empty map.\"\"\"\n",
    "    self._table = []                              # list of _Item's\n",
    "  \n",
    "  def __getitem__(self, k):\n",
    "    \"\"\"Return value associated with key k (raise KeyError if not found).\"\"\"\n",
    "    for item in self._table:\n",
    "      if k == item._key:\n",
    "        return item._value\n",
    "    raise KeyError('Key Error: ' + repr(k))\n",
    "\n",
    "  def __setitem__(self, k, v):\n",
    "    \"\"\"Assign value v to key k, overwriting existing value if present.\"\"\"\n",
    "    for item in self._table:\n",
    "      if k == item._key:                          # Found a match:\n",
    "        item._value = v                           # reassign value\n",
    "        return                                    # and quit    \n",
    "    # did not find match for key\n",
    "    self._table.append(self._Item(k,v))\n",
    "\n",
    "  def __delitem__(self, k):\n",
    "    \"\"\"Remove item associated with key k (raise KeyError if not found).\"\"\"\n",
    "    for j in range(len(self._table)):\n",
    "      if k == self._table[j]._key:                # Found a match:\n",
    "        self._table.pop(j)                        # remove item\n",
    "        return                                    # and quit    \n",
    "    raise KeyError('Key Error: ' + repr(k))\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"Return number of items in the map.\"\"\"\n",
    "    return len(self._table)\n",
    "\n",
    "  def __iter__(self):                             \n",
    "    \"\"\"Generate iteration of the map's keys.\"\"\"\n",
    "    for item in self._table:\n",
    "      yield item._key                             # yield the KEY\n",
    "\n",
    "class HashMapBase(MapBase):\n",
    "    \"\"\" Abstract base class for map using hash-table with MAD compression.\n",
    "    Keys must be hashable and non-None.\n",
    "    \"\"\"\n",
    "    def __init__(self, cap=11, p=109345121):\n",
    "        \"\"\"Create an empty hash-table map.\n",
    "        cap initial table size (default 11)\n",
    "        p positive prime used for MAD (default 109345121)\n",
    "        \"\"\"\n",
    "        self._table = cap * [ None ]\n",
    "        self._n = 0 # number of entries in the map\n",
    "        self._prime = p # prime for MAD compression\n",
    "        self._scale = 1 + randrange(p-1) # scale from 1 to p-1 for MAD\n",
    "        self._shift = randrange(p) # shift from 0 to p-1 for MAD\n",
    "    def _hash_function(self, k):\n",
    "        return (hash(k)*self._scale + self._shift) % self._prime % len(self._table)\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "    def __getitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        return self._bucket_getitem(j, k) # may raise KeyError\n",
    "    def __setitem__(self, k, v):\n",
    "        j = self._hash_function(k)\n",
    "\n",
    "        self._bucket_setitem(j, k, v) # subroutine maintains self._n\n",
    "        if self._n > len(self._table) // 2: # keep load factor <= 0.5\n",
    "            self._resize(2 * len(self._table) - 1) # number 2^x - 1 is often prime\n",
    "    def __delitem__(self, k):\n",
    "        j = self._hash_function(k)\n",
    "        self._bucket_delitem(j, k) # may raise KeyError\n",
    "        self._n -= 1\n",
    "        \n",
    "    def _resize(self, c):\n",
    "        \"\"\"Resize bucket array to capacity c and rehash all items.\"\"\"\n",
    "        old = list(self.items()) # use iteration to record existing items\n",
    "        self._table = c * [None] # then reset table to desired capacity\n",
    "        self._n = 0 # n recomputed during subsequent adds\n",
    "        for (k,v) in old:\n",
    "            self[k] = v # reinsert old key-value pair\n",
    "\n",
    "class ChainHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with separate chaining for collision resolution.\"\"\"\n",
    "    def _bucket_getitem(self, j, k):\n",
    "        #================================================================================\n",
    "        #j = collision_hash(j) do zadania 3\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k)) # no match found\n",
    "        return bucket[k] # may raise KeyError\n",
    "    \n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        #j = collision_hash(j)\n",
    "        if self._table[j] is None:\n",
    "            self._table[j] = UnsortedTableMap() # bucket is new to the table\n",
    "        oldsize = len(self._table[j])\n",
    "        self._table[j][k] = v\n",
    "        if len(self._table[j]) > oldsize: # key was new to the table\n",
    "            self._n += 1 # increase overall map size\n",
    "    \n",
    "    def _bucket_delitem(self, j, k):\n",
    "        bucket = self._table[j]\n",
    "        if bucket is None:\n",
    "            raise KeyError('Key Error: ' + repr(k)) # no match found\n",
    "        del bucket[k]               # may raise KeyError\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for bucket in self._table:\n",
    "            if bucket is not None: # a nonempty slot\n",
    "                for key in bucket:\n",
    "                    yield key\n",
    "\n",
    "class ProbeHashMap(HashMapBase):\n",
    "    \"\"\"Hash map implemented with linear probing for collision resolution.\"\"\"\n",
    "    _AVAIL = object() # sentinal marks locations of previous deletions\n",
    "    def _is_available(self, j):\n",
    "        \"\"\"Return True if index j is available in table.\"\"\"\n",
    "        return self._table[j] is None or self._table[j] is ProbeHashMap._AVAIL\n",
    "    def _find_slot(self, j, k):\n",
    "        \"\"\"Search for key k in bucket at index j.\n",
    "        Return (success, index) tuple, described as follows:\n",
    "        If match was found, success is True and index denotes its location.\n",
    "        If no match found, success is False and index denotes first available slot.\n",
    "        \"\"\"\n",
    "        firstAvail = None\n",
    "        while True:\n",
    "            if self._is_available(j):\n",
    "                if firstAvail is None:\n",
    "                    firstAvail = j # mark this as first avail\n",
    "                if self._table[j] is None:\n",
    "                    return (False, firstAvail) # search has failed\n",
    "            elif k == self._table[j]._key:\n",
    "                return (True, j) # found a match\n",
    "            j = (j + 1) % len(self._table) # keep looking (cyclically)\n",
    "    \n",
    "    def _bucket_getitem(self, j, k):\n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError('Key Error: ' + repr(k)) # no match found\n",
    "        return self._table[s]._value\n",
    "    \n",
    "    def _bucket_setitem(self, j, k, v):\n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            self._table[s] = self._Item(k,v) # insert new item\n",
    "            self._n += 1 # size has increased\n",
    "        else:\n",
    "            self._table[s]._value = v # overwrite existing\n",
    "    \n",
    "    def _bucket_delitem(self, j, k):\n",
    "        found, s = self._find_slot(j, k)\n",
    "        if not found:\n",
    "            raise KeyError('Key Error: ' + repr(k)) # no match found\n",
    "        self._table[s] = ProbeHashMap._AVAIL # mark as vacated\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for j in range(len(self._table)): # scan entire table\n",
    "            if not self._is_available(j):\n",
    "                yield self._table[j]._key\n",
    "\n",
    "\n",
    "def collision_hash(k):\n",
    "    \n",
    "    return 7-(k % 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13, 0], [94, 1], [39, 1], [44, 5], [88, 5], [11, 5], [12, 8], [23, 8], [16, 9], [5, 9], [20, 10]]\n"
     ]
    }
   ],
   "source": [
    "tab_asoc = ChainHashMap(cap = 11, p = 11)\n",
    "tab_asoc._scale = 3\n",
    "tab_asoc._shift = 5\n",
    "\n",
    "tab_asoc[12] = \"12\"\n",
    "tab_asoc[44] = \"44\"\n",
    "tab_asoc[13] = \"13\"\n",
    "tab_asoc[88] = \"88\"\n",
    "tab_asoc[23] = \"23\"\n",
    "tab_asoc[94] = \"94\"\n",
    "tab_asoc[11] = \"11\"\n",
    "tab_asoc[39] = \"39\"\n",
    "tab_asoc[20] = \"20\"\n",
    "tab_asoc[16] = \"16\"\n",
    "tab_asoc[5] = \"5\"\n",
    "\n",
    "indexes = []\n",
    "for key in tab_asoc.keys():\n",
    "    indexes.append([key,tab_asoc._hash_function(key)])\n",
    "    \n",
    "print(indexes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13, 0], [94, 1], [39, 2], [44, 5], [88, 6], [11, 7], [12, 8], [23, 9], [20, 10], [16, 11], [5, 12]]\n"
     ]
    }
   ],
   "source": [
    "tab_asoc = ProbeHashMap(cap = 11, p = 11)\n",
    "tab_asoc._scale = 3\n",
    "tab_asoc._shift = 5\n",
    "\n",
    "tab_asoc[12] = \"12\"\n",
    "tab_asoc[44] = \"44\"\n",
    "tab_asoc[13] = \"13\"\n",
    "tab_asoc[88] = \"88\"\n",
    "tab_asoc[23] = \"23\"\n",
    "tab_asoc[94] = \"94\"\n",
    "tab_asoc[11] = \"11\"\n",
    "tab_asoc[39] = \"39\"\n",
    "tab_asoc[20] = \"20\"\n",
    "tab_asoc[16] = \"16\"\n",
    "tab_asoc[5] = \"5\"\n",
    "\n",
    "indexes = []\n",
    "for key in tab_asoc.keys():\n",
    "    indexes.append([key,tab_asoc._find_slot(tab_asoc._hash_function(key),key)[1]])\n",
    "    \n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44, 2], [88, 2], [11, 2], [20, 4], [16, 5], [5, 5], [12, 6], [23, 6], [94, 6], [39, 6], [13, 7]]\n"
     ]
    }
   ],
   "source": [
    "tab_asoc = ChainHashMap(cap = 11, p = 11)\n",
    "tab_asoc._scale = 3\n",
    "tab_asoc._shift = 5\n",
    "\n",
    "tab_asoc[12] = \"12\"\n",
    "tab_asoc[44] = \"44\"\n",
    "tab_asoc[13] = \"13\"\n",
    "tab_asoc[88] = \"88\"\n",
    "tab_asoc[23] = \"23\"\n",
    "tab_asoc[94] = \"94\"\n",
    "tab_asoc[11] = \"11\"\n",
    "tab_asoc[39] = \"39\"\n",
    "tab_asoc[20] = \"20\"\n",
    "tab_asoc[16] = \"16\"\n",
    "tab_asoc[5] = \"5\"\n",
    "\n",
    "indexes = []\n",
    "for key in tab_asoc.keys():\n",
    "    indexes.append([key,collision_hash(tab_asoc._hash_function(key))])\n",
    "    \n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"zad4.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"zad5_2.jpg\">\n",
    "<img src=\"zad5_1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_name(tab,l,r):\n",
    "    \"\"\"Sortuje tablicę tab oraz zwraca index pivota, elementu według którego sortowano\"\"\"\n",
    "    i = l\n",
    "    pivot = tab[r]\n",
    "    for j in range(l,r):\n",
    "        if tab[j] <= pivot:\n",
    "            tab[i], tab[j] = tab[j], tab[i]\n",
    "            i += 1\n",
    "    tab[i],tab[r] = tab[r],tab[i]\n",
    "    return i\n",
    "\n",
    "def quick_non_recursive(tab,l,r):\n",
    "    \"\"\"Szybkie sortowanie które używa stosu do przechowywania indeksów partycji nieposortowanych\"\"\"\n",
    "    # we will use a stack to manage the indexes of partitions\n",
    "    size = r - l + 1\n",
    "    stack = [0] * size\n",
    "    top = -1\n",
    "\n",
    "    # we start with the given left and right values\n",
    "    top += 1\n",
    "    stack[top] = l\n",
    "    top += 1\n",
    "    stack[top] = r\n",
    "    \n",
    "    #we sort in bounds of the left and right values given on the stack till nothing is left\n",
    "    while top >= 0:\n",
    "\n",
    "        r = stack[top]\n",
    "        top -= 1\n",
    "        l = stack[top]\n",
    "        top -= 1\n",
    "\n",
    "        pivot = sort_name(tab,l,r)\n",
    "        #if there are unsorted elements on the left or right of the pivot we add new bounds to the stack\n",
    "        if pivot+1 < r:\n",
    "            top += 1\n",
    "            stack[top] = pivot+1\n",
    "            top += 1\n",
    "            stack[top] = r\n",
    "        \n",
    "        if pivot-1 > l:\n",
    "            top += 1\n",
    "            stack[top] = l\n",
    "            top += 1\n",
    "            stack[top] = pivot -1\n",
    "\n",
    "\n",
    "def quick_in_place(array,l,r):\n",
    "    \"\"\"Sortowanie szybkie in-place które używa rekurencji by określać kolejne indexy partycji do posortowania\"\"\"\n",
    "    p = sort_name(array,l,r)\n",
    "    if p+1 < r:\n",
    "        quick_in_place(array,p+1,r)\n",
    "    if p-1 > l:\n",
    "        quick_in_place(array,l,p-1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 6, 7, 9]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 10, 14]\n"
     ]
    }
   ],
   "source": [
    "array = [3,7,6,1,2,9,5]\n",
    "array2 = [7,2,6,10,4,14,8,3,1,5]\n",
    "quick_non_recursive(array,0,len(array)-1)\n",
    "quick_in_place(array2,0,len(array2)-1)\n",
    "print(array)\n",
    "print(array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 10, 14]\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def insert_sort_anim(arr):\n",
    "    \"\"\"Animowanie sortowania bąbelkowego\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    n= len(arr)\n",
    "    def update(frame):\n",
    "        \"\"\"Sortowanie bąbelkowe\"\"\"\n",
    "        i = frame%(n-1)\n",
    "        ax.clear()\n",
    "        if arr[i] > arr[i+1]:\n",
    "            arr[i],arr[i+1] = arr[i+1], arr[i]\n",
    "        \n",
    "        ax.bar(range(0,len(arr)),arr)\n",
    "\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames= (n-1)* n, repeat=False)\n",
    "    ani.save(\"animacja.gif\")\n",
    "    plt.close()\n",
    "    print(arr)\n",
    "\n",
    "\n",
    "y = [7,2,6,10,4,14,8,3,1,5]\n",
    "insert_sort_anim(y)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
